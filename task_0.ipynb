{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "overhead-clinic",
   "metadata": {},
   "source": [
    "# Part 0: Dataloader and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moved-crisis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/vlr/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "\n",
    "from voc_dataset import VOCDataset\n",
    "from utils import *\n",
    "\n",
    "USE_WANDB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-prague",
   "metadata": {},
   "source": [
    "## Q0.1: Editing the Dataloader\n",
    "The first part of the assignment involves editing the dataloader so that we can access bounding-box proposals as well as the ground-truth bounding boxes. The ground truth bounding box can be accessed through the VOC Dataset annotations itself and we have completed this part for you in the starter code. \n",
    "\n",
    "Unsupervised bounding box proposals are obtained through methods such as [Selective Search](https://ivi.fnwi.uva.nl/isis/publications/2013/UijlingsIJCV2013/UijlingsIJCV2013.pdf). Since Selective Search is slow to run on each image, we have pre-computed the bounding box proposals for you (you downloaded this in the data preparation step).\n",
    "\n",
    "Your task is to change the dataloader to obtain the proposed bounding boxes for each image. Feel free to experiment with the data in the files to figure out the number of proposals per image, their scores, etc. Returning a dictionary would be convenient here. For the bounding boxes, using the relative positions is usually a better idea since they are invariant to changes in the size of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thousand-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VOCDataset('trainval', top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2223be0",
   "metadata": {},
   "source": [
    "**Q0.1**: Load the image corresponding to index 2020 and print the GT labels associated with it.\n",
    "\n",
    "**Hint**: items at a particular index can be accesed by usual indexing notation (dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "confused-witness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is [[0.374, 0.002680965147453083, 0.958, 0.5898123324396782], [0.374, 0.5120643431635389, 0.762, 0.7855227882037533], [0.172, 0.002680965147453083, 0.962, 0.579088471849866], [0.372, 0.5120643431635389, 0.762, 0.6863270777479893], [0.514, 0.002680965147453083, 0.958, 0.514745308310992], [0.372, 0.4745308310991957, 0.726, 0.8900804289544236], [0.254, 0.3109919571045576, 0.726, 0.5817694369973191], [0.378, 0.48525469168900803, 0.8, 0.8605898123324397], [0.862, 0.002680965147453083, 1.0, 0.46380697050938335], [0.286, 0.49865951742627346, 0.764, 0.8284182305630027]]\n",
      "train\n"
     ]
    }
   ],
   "source": [
    "# TODO: get the image information from index 2020\n",
    "idx = 2020\n",
    "result =  dataset[idx]\n",
    "print(\"result is\", result['rois']['top_boxes'])\n",
    "print(dataset.get_class_name(result['gt_classes'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-recycling",
   "metadata": {},
   "source": [
    "## Q0.2 and Q0.3: Wandb Logging\n",
    "First, let's initialize a Weights and Biases project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "conventional-flexibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2vluxemx) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">driven-brook-8</strong>: <a href=\"https://wandb.ai/ziweny/vlr-hw1/runs/2vluxemx\" target=\"_blank\">https://wandb.ai/ziweny/vlr-hw1/runs/2vluxemx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220930_025504-2vluxemx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2vluxemx). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/data/object-localization/wandb/run-20220930_025517-3ed7xwtd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ziweny/vlr-hw1/runs/3ed7xwtd\" target=\"_blank\">brisk-bee-9</a></strong> to <a href=\"https://wandb.ai/ziweny/vlr-hw1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "USE_WANDB = True\n",
    "if USE_WANDB:\n",
    "    wandb.init(project=\"vlr-hw1\", reinit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-ladder",
   "metadata": {},
   "source": [
    "**Q0.2**: Complete this block for overlaying the ground truth box on an image.\n",
    "\n",
    "**Hint**: convert the image tensor to a PIL image and plot it (check `utils.py` for helper functions). You can use [this](https://docs.wandb.ai/library/log) as a reference for logging syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "resistant-concert",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2477532189.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_5997/2477532189.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    original_image =\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class_id_to_label = dict(enumerate(dataset.CLASS_NAMES))\n",
    "\n",
    "# TODO: load the GT information corresponding to index 2020.\n",
    "original_image = result['image']\n",
    "gt_labels = result['gt_classes']\n",
    "gt_boxes = result['gt_boxes']\n",
    "\n",
    "img = wandb.Image(original_image, boxes={\n",
    "    \"predictions\": {\n",
    "        \"box_data\": get_box_data(gt_labels, gt_boxes),\n",
    "        \"class_labels\": class_id_to_label,\n",
    "    },\n",
    "})\n",
    "\n",
    "# TODO: log the GT bounding box\n",
    "wandb.log({\"bounding box\": img})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-thread",
   "metadata": {},
   "source": [
    "**Q0.3**: Visualize the top 10 bounding proposals corresponding to index 2020.\n",
    "\n",
    "**Hint**: Check the `get_box_data` function in `utils.py` and understand how it is being used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot top ten proposals (of bounding boxes)\n",
    "roi_boxes = result['rois']['top_boxes']\n",
    "roi_labels = [0] * len(roi_boxes)\n",
    "\n",
    "img_roi = wandb.Image(original_image, boxes={\n",
    "    \"predictions\": {\n",
    "        \"box_data\": get_box_data(roi_labels, roi_boxes)\n",
    "    },\n",
    "})\n",
    "wandb.log({\"top n roi boxes\": img_roi})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('vlr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b6cfe6bcfe7ae95ab276f1fd29b9a081a34e29b17337b83b3051e8152452b07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
